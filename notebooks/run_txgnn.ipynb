{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\network-analysis-project\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]\n",
      "Torch version: 2.8.0+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# TxGNN Subgraph Training and Evaluation\n",
    "\n",
    "# --- Imports and environment check ---\n",
    "import torch\n",
    "from txgnn import TxData, TxGNN, TxEval\n",
    "import os, sys\n",
    "\n",
    "print('Python version:', sys.version)\n",
    "print('Torch version:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config ---\n",
    "\n",
    "# Path to a subgraph folder (e.g., drug-disease-gene subgraph)\n",
    "DATA_DIR = '../data/subgraphs/drug-disease-gene'\n",
    "\n",
    "# Device\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Seeds and save paths\n",
    "SEED = 42\n",
    "SAVE_MODEL_PATH = './finetune_subgraph.pt'\n",
    "SAVE_EVAL_PATH = './eval_subgraph'\n",
    "\n",
    "# Model dimensions (small for Colab / CPU)\n",
    "N_HID, N_INP, N_OUT = 64, 64, 64\n",
    "PROTO, PROTO_NUM = True, 2\n",
    "ATTN = False\n",
    "SIM_MEASURE = 'all_nodes_profile'\n",
    "AGG_MEASURE = 'rarity'\n",
    "NUM_WALKS, PATH_LEN = 50, 2\n",
    "\n",
    "# Training schedule\n",
    "PRETRAIN_EPOCHS = 1      # 0 to skip pretrain\n",
    "PRETRAIN_LR = 1e-3\n",
    "PRETRAIN_BATCH = 512\n",
    "FINETUNE_EPOCHS = 30\n",
    "FINETUNE_LR = 5e-4\n",
    "TRAIN_PRINT_N = 10\n",
    "VALID_EVERY_N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: ../data/subgraphs/drug-disease-gene\n",
      "Found local copy...\n",
      "Found local copy...\n",
      "Found local copy...\n",
      "Found saved processed KG... Loading...\n",
      "Splits detected... Loading splits....\n",
      "Creating DGL graph....\n",
      "Done!\n",
      "Data ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Load data and prepare split ---\n",
    "print('Loading data from:', DATA_DIR)\n",
    "TxDataObj = TxData(data_folder_path=DATA_DIR)\n",
    "TxDataObj.prepare_split(split='full_graph', seed=SEED)\n",
    "print('Data ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized on cpu\n"
     ]
    }
   ],
   "source": [
    "# --- Initialize model ---\n",
    "Tx = TxGNN(\n",
    "    data=TxDataObj,\n",
    "    weight_bias_track=False,\n",
    "    proj_name='TxGNN',\n",
    "    exp_name='subgraph_notebook',\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "Tx.model_initialize(\n",
    "    n_hid=N_HID,\n",
    "    n_inp=N_INP,\n",
    "    n_out=N_OUT,\n",
    "    proto=PROTO,\n",
    "    proto_num=PROTO_NUM,\n",
    "    attention=ATTN,\n",
    "    sim_measure=SIM_MEASURE,\n",
    "    agg_measure=AGG_MEASURE,\n",
    "    num_walks=NUM_WALKS,\n",
    "    path_length=PATH_LEN,\n",
    ")\n",
    "print('Model initialized on', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pretraining...\n",
      "Creating minibatch pretraining dataloader...\n",
      "Start pre-training with #param: 419200\n",
      "Epoch: 0 Step: 0 LR: 0.00100 Loss 0.6945, Pretrain Micro AUROC 0.4759 Pretrain Micro AUPRC 0.4867 Pretrain Macro AUROC 0.4447 Pretrain Macro AUPRC 0.5878\n",
      "Epoch: 0 Step: 10 LR: 0.00100 Loss 0.6871, Pretrain Micro AUROC 0.5748 Pretrain Micro AUPRC 0.5821 Pretrain Macro AUROC 0.5700 Pretrain Macro AUPRC 0.6945\n",
      "Epoch: 0 Step: 20 LR: 0.00100 Loss 0.6833, Pretrain Micro AUROC 0.5875 Pretrain Micro AUPRC 0.5855 Pretrain Macro AUROC 0.5832 Pretrain Macro AUPRC 0.6786\n",
      "Epoch: 0 Step: 30 LR: 0.00100 Loss 0.6779, Pretrain Micro AUROC 0.6074 Pretrain Micro AUPRC 0.5946 Pretrain Macro AUROC 0.5940 Pretrain Macro AUPRC 0.7044\n",
      "Epoch: 0 Step: 40 LR: 0.00100 Loss 0.6733, Pretrain Micro AUROC 0.6039 Pretrain Micro AUPRC 0.5972 Pretrain Macro AUROC 0.5984 Pretrain Macro AUPRC 0.7030\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PRETRAIN_EPOCHS \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting pretraining...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mTx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPRETRAIN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPRETRAIN_LR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPRETRAIN_BATCH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_print_per_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAIN_PRINT_N\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkipping pretrain step.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\dev\\network-analysis-project\\venv\\lib\\site-packages\\txgnn\\TxGNN.py:180\u001b[0m, in \u001b[0;36mTxGNN.pretrain\u001b[1;34m(self, n_epoch, learning_rate, batch_size, train_print_per_n, sweep_wandb)\u001b[0m\n\u001b[0;32m    178\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(scores, torch\u001b[38;5;241m.\u001b[39mTensor(labels)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m    179\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 180\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_bias_track:\n",
      "File \u001b[1;32mc:\\dev\\network-analysis-project\\venv\\lib\\site-packages\\torch\\_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    646\u001b[0m     )\n\u001b[1;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\network-analysis-project\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\network-analysis-project\\venv\\lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    830\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    831\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[1;32mc:\\dev\\network-analysis-project\\venv\\lib\\site-packages\\torch\\autograd\\function.py:311\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m     )\n\u001b[0;32m    310\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\network-analysis-project\\venv\\lib\\site-packages\\dgl\\backend\\pytorch\\sparse.py:215\u001b[0m, in \u001b[0;36mGSpMM.backward\u001b[1;34m(ctx, dZ)\u001b[0m\n\u001b[0;32m    213\u001b[0m         dX \u001b[38;5;241m=\u001b[39m gspmm(g_rev, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy_lhs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m, dZ, Y)\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m op \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy_lhs\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         dX \u001b[38;5;241m=\u001b[39m \u001b[43mgspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_rev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy_lhs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# max/min\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     dX \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m    218\u001b[0m         (X_shape[\u001b[38;5;241m0\u001b[39m],) \u001b[38;5;241m+\u001b[39m dZ\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:], dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m    219\u001b[0m     )\n",
      "File \u001b[1;32mc:\\dev\\network-analysis-project\\venv\\lib\\site-packages\\dgl\\backend\\pytorch\\sparse.py:1032\u001b[0m, in \u001b[0;36mgspmm\u001b[1;34m(gidx, op, reduce_op, lhs_data, rhs_data)\u001b[0m\n\u001b[0;32m   1030\u001b[0m args \u001b[38;5;241m=\u001b[39m _cast_if_autocast_enabled(gidx, op, reduce_op, lhs_data, rhs_data)\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _disable_autocast_if_enabled():\n\u001b[1;32m-> 1032\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGSpMM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\network-analysis-project\\venv\\lib\\site-packages\\torch\\autograd\\function.py:576\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    575\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m     )\n",
      "File \u001b[1;32mc:\\dev\\network-analysis-project\\venv\\lib\\site-packages\\dgl\\backend\\pytorch\\sparse.py:165\u001b[0m, in \u001b[0;36mGSpMM.forward\u001b[1;34m(ctx, gidx, op, reduce_op, X, Y)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(ctx, gidx, op, reduce_op, X, Y):\n\u001b[1;32m--> 165\u001b[0m     out, (argX, argY) \u001b[38;5;241m=\u001b[39m \u001b[43m_gspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     reduce_last \u001b[38;5;241m=\u001b[39m _need_reduce_last_dim(X, Y)\n\u001b[0;32m    167\u001b[0m     X_shape \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\network-analysis-project\\venv\\lib\\site-packages\\dgl\\_sparse_ops.py:239\u001b[0m, in \u001b[0;36m_gspmm\u001b[1;34m(gidx, op, reduce_op, u, e)\u001b[0m\n\u001b[0;32m    237\u001b[0m arg_e_nd \u001b[38;5;241m=\u001b[39m to_dgl_nd_for_write(arg_e)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gidx\u001b[38;5;241m.\u001b[39mnum_edges(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 239\u001b[0m     \u001b[43m_CAPI_DGLKernelSpMM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgidx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_dgl_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_u\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_dgl_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_e\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_dgl_nd_for_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_u_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_e_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# NOTE(zihao): actually we can avoid the following step, because arg_*_nd\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# refers to the data that stores arg_*. After we call _CAPI_DGLKernelSpMM,\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# arg_* should have already been changed. But we found this doesn't work\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m# The workaround is proposed by Jinjing, and we still need to investigate\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# where the problem is.\u001b[39;00m\n\u001b[0;32m    256\u001b[0m arg_u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m arg_u \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m F\u001b[38;5;241m.\u001b[39mzerocopy_from_dgl_ndarray(arg_u_nd)\n",
      "File \u001b[1;32mc:\\dev\\network-analysis-project\\venv\\lib\\site-packages\\dgl\\_ffi\\_ctypes\\function.py:213\u001b[0m, in \u001b[0;36mFunctionBase.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    210\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m DGLValue()\n\u001b[0;32m    211\u001b[0m ret_tcode \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_int()\n\u001b[0;32m    212\u001b[0m check_call(\n\u001b[1;32m--> 213\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDGLFuncCall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtcodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_tcode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m )\n\u001b[0;32m    222\u001b[0m _ \u001b[38;5;241m=\u001b[39m temp_args\n\u001b[0;32m    223\u001b[0m _ \u001b[38;5;241m=\u001b[39m args\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Optional pretraining ---\n",
    "if PRETRAIN_EPOCHS > 0:\n",
    "    print('Starting pretraining...')\n",
    "    Tx.pretrain(\n",
    "        n_epoch=PRETRAIN_EPOCHS,\n",
    "        learning_rate=PRETRAIN_LR,\n",
    "        batch_size=PRETRAIN_BATCH,\n",
    "        train_print_per_n=TRAIN_PRINT_N,\n",
    "    )\n",
    "else:\n",
    "    print('Skipping pretrain step.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Finetune on drugâ€“disease prediction ---\n",
    "print('Starting finetune...')\n",
    "Tx.finetune(\n",
    "    n_epoch=FINETUNE_EPOCHS,\n",
    "    learning_rate=FINETUNE_LR,\n",
    "    train_print_per_n=TRAIN_PRINT_N,\n",
    "    valid_per_n=VALID_EVERY_N,\n",
    "    save_name=SAVE_MODEL_PATH,\n",
    ")\n",
    "print('Finetune complete. Model saved to', SAVE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluate ---\n",
    "print('Evaluating...')\n",
    "TxE = TxEval(model=Tx)\n",
    "results = TxE.eval_disease_centric(\n",
    "    disease_idxs='test_set',\n",
    "    show_plot=False,\n",
    "    verbose=True,\n",
    "    save_result=True,\n",
    "    return_raw=False,\n",
    "    save_name=SAVE_EVAL_PATH,\n",
    ")\n",
    "print('\\nEvaluation summary:')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Notes\n",
    "- You can re-run this notebook for different subgraph folders by changing `DATA_DIR` at the top.\n",
    "- The printed output and metrics will remain visible in the `.ipynb` file after saving, so your professor can see the training/evaluation logs.\n",
    "- For faster testing on CPU, reduce `FINETUNE_EPOCHS` or skip pretraining."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
