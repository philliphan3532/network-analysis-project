{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8278b7c7",
   "metadata": {},
   "source": [
    "\n",
    "# Subgraph Link Prediction Heuristics\n",
    "\n",
    "This notebook computes link prediction heuristics for every prepared subgraph under `data/subgraphs`. For each subgraph we report the common neighbors count, Jaccard coefficient, Adamicâ€“Adar index, and a network proximity z-score for all observed edges. Adjust the helper code if you want to look at non-edge pairs or persist the results to disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ea37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import math\n",
    "import random\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb4927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Resolve project paths so the notebook works when launched from the repo root or the notebooks folder.\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if not (PROJECT_ROOT / 'data').exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent.resolve()\n",
    "\n",
    "SUBGRAPH_ROOT = PROJECT_ROOT / 'data' / 'subgraphs'\n",
    "if not SUBGRAPH_ROOT.exists():\n",
    "    raise FileNotFoundError(f'Expected subgraphs under {SUBGRAPH_ROOT}')\n",
    "\n",
    "subgraph_dirs = sorted(p for p in SUBGRAPH_ROOT.glob('*') if p.is_dir())\n",
    "print(f\"Found {len(subgraph_dirs)} subgraph(s):\")\n",
    "for path in subgraph_dirs:\n",
    "    print(f\" - {path.relative_to(PROJECT_ROOT)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a949fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_subgraph(subgraph_path: Path):\n",
    "    \"\"\"Return node and edge tables for a subgraph directory.\"\"\"\n",
    "    nodes = pd.read_csv(subgraph_path / 'node.csv', sep='\t', dtype={'node_index': str})\n",
    "    edges = pd.read_csv(\n",
    "        subgraph_path / 'edges.csv',\n",
    "        dtype={'x_index': str, 'y_index': str, 'relation': str, 'display_relation': str},\n",
    "    )\n",
    "    return nodes, edges\n",
    "\n",
    "\n",
    "def build_graph(nodes: pd.DataFrame, edges: pd.DataFrame) -> nx.Graph:\n",
    "    \"\"\"Construct an undirected graph from node and edge tables.\"\"\"\n",
    "    graph = nx.Graph()\n",
    "    for row in nodes.itertuples(index=False):\n",
    "        graph.add_node(row.node_index, node_type=row.node_type, node_name=row.node_name)\n",
    "\n",
    "    for row in edges.itertuples(index=False):\n",
    "        graph.add_edge(row.x_index, row.y_index, relation=row.relation)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def compute_link_metrics(\n",
    "    graph: nx.Graph,\n",
    "    nodes: pd.DataFrame,\n",
    "    edges: pd.DataFrame,\n",
    "    *,\n",
    "    proximity_samples: int = 200,\n",
    "    seed: int = 42,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compute link prediction heuristics for every observed edge.\"\"\"\n",
    "    type_map = nodes.set_index('node_index')['node_type'].to_dict()\n",
    "    name_map = nodes.set_index('node_index')['node_name'].to_dict()\n",
    "    degree_map = dict(graph.degree())\n",
    "    nodes_by_type = nodes.groupby('node_type')['node_index'].apply(list).to_dict()\n",
    "\n",
    "    rng = random.Random(seed)\n",
    "    shortest_path_cache: dict[str, dict[str, int]] = {}\n",
    "\n",
    "    def shortest_path_length(u: str, v: str) -> float:\n",
    "        if u not in shortest_path_cache:\n",
    "            shortest_path_cache[u] = nx.single_source_shortest_path_length(graph, u)\n",
    "        return shortest_path_cache[u].get(v, math.inf)\n",
    "\n",
    "    baseline_cache: dict[tuple[str, str], tuple[float, float] | None] = {}\n",
    "\n",
    "    def proximity_baseline(type_u: str, type_v: str):\n",
    "        key = (type_u, type_v)\n",
    "        if key in baseline_cache:\n",
    "            return baseline_cache[key]\n",
    "\n",
    "        candidates_u = nodes_by_type.get(type_u, [])\n",
    "        candidates_v = nodes_by_type.get(type_v, [])\n",
    "        if not candidates_u or not candidates_v:\n",
    "            baseline_cache[key] = None\n",
    "            baseline_cache[(type_v, type_u)] = None\n",
    "            return None\n",
    "\n",
    "        samples: list[float] = []\n",
    "        seen_pairs: set[tuple[str, str]] = set()\n",
    "        max_attempts = proximity_samples * 10\n",
    "        attempts = 0\n",
    "\n",
    "        while len(samples) < proximity_samples and attempts < max_attempts:\n",
    "            attempts += 1\n",
    "            u = rng.choice(candidates_u)\n",
    "            v = rng.choice(candidates_v)\n",
    "            if u == v:\n",
    "                continue\n",
    "            pair_key = (u, v) if type_u != type_v else tuple(sorted((u, v)))\n",
    "            if pair_key in seen_pairs:\n",
    "                continue\n",
    "            seen_pairs.add(pair_key)\n",
    "\n",
    "            dist = shortest_path_length(u, v)\n",
    "            if math.isinf(dist):\n",
    "                continue\n",
    "            samples.append(dist)\n",
    "\n",
    "        if len(samples) < 2:\n",
    "            baseline_cache[key] = None\n",
    "            baseline_cache[(type_v, type_u)] = None\n",
    "            return None\n",
    "\n",
    "        mean_dist = float(np.mean(samples))\n",
    "        std_dist = float(np.std(samples, ddof=1)) if len(samples) > 1 else 0.0\n",
    "        baseline_cache[key] = (mean_dist, std_dist)\n",
    "        baseline_cache[(type_v, type_u)] = (mean_dist, std_dist)\n",
    "        return baseline_cache[key]\n",
    "\n",
    "    edge_pairs = [(row.x_index, row.y_index) for row in edges.itertuples(index=False)]\n",
    "\n",
    "    jaccard_scores = {}\n",
    "    for u, v, score in nx.jaccard_coefficient(graph, edge_pairs):\n",
    "        jaccard_scores[(u, v)] = score\n",
    "        jaccard_scores[(v, u)] = score\n",
    "\n",
    "    adamic_scores = {}\n",
    "    for u, v, score in nx.adamic_adar_index(graph, edge_pairs):\n",
    "        adamic_scores[(u, v)] = score\n",
    "        adamic_scores[(v, u)] = score\n",
    "\n",
    "    records = []\n",
    "    for row in edges.itertuples(index=False):\n",
    "        u = row.x_index\n",
    "        v = row.y_index\n",
    "        source_type = type_map.get(u)\n",
    "        target_type = type_map.get(v)\n",
    "\n",
    "        cn_count = sum(1 for _ in nx.common_neighbors(graph, u, v))\n",
    "\n",
    "        jaccard_score = jaccard_scores.get((u, v), float('nan'))\n",
    "        adamic_score = adamic_scores.get((u, v), float('nan'))\n",
    "\n",
    "        sp_length = shortest_path_length(u, v)\n",
    "        if math.isinf(sp_length):\n",
    "            proximity_z = None\n",
    "            baseline_mean = None\n",
    "            baseline_std = None\n",
    "            sp_value = None\n",
    "        else:\n",
    "            baseline = proximity_baseline(source_type, target_type)\n",
    "            if baseline is None:\n",
    "                proximity_z = None\n",
    "                baseline_mean = None\n",
    "                baseline_std = None\n",
    "            else:\n",
    "                mean_dist, std_dist = baseline\n",
    "                if std_dist > 0:\n",
    "                    proximity_z = (sp_length - mean_dist) / std_dist\n",
    "                else:\n",
    "                    proximity_z = 0.0\n",
    "                baseline_mean = mean_dist\n",
    "                baseline_std = std_dist\n",
    "            sp_value = sp_length\n",
    "\n",
    "        records.append(\n",
    "            {\n",
    "                'source_index': u,\n",
    "                'target_index': v,\n",
    "                'source_type': source_type,\n",
    "                'target_type': target_type,\n",
    "                'source_name': name_map.get(u),\n",
    "                'target_name': name_map.get(v),\n",
    "                'relation': row.relation,\n",
    "                'common_neighbors': cn_count,\n",
    "                'jaccard_coefficient': jaccard_score,\n",
    "                'adamic_adar_index': adamic_score,\n",
    "                'shortest_path_length': sp_value,\n",
    "                'network_proximity_z': proximity_z,\n",
    "                'proximity_baseline_mean': baseline_mean,\n",
    "                'proximity_baseline_std': baseline_std,\n",
    "                'source_degree': degree_map.get(u),\n",
    "                'target_degree': degree_map.get(v),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame.from_records(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6975d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {}\n",
    "for subgraph_path in subgraph_dirs:\n",
    "    nodes_df, edges_df = load_subgraph(subgraph_path)\n",
    "    graph = build_graph(nodes_df, edges_df)\n",
    "    metrics_df = compute_link_metrics(graph, nodes_df, edges_df)\n",
    "    key = subgraph_path.name\n",
    "    results[key] = {\n",
    "        'graph': graph,\n",
    "        'nodes': nodes_df,\n",
    "        'edges': edges_df,\n",
    "        'metrics': metrics_df,\n",
    "    }\n",
    "    print(f\"Computed metrics for {key}: {len(metrics_df)} edge(s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preview the first few rows for one subgraph.\n",
    "example_key = next(iter(results))\n",
    "results[example_key]['metrics'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d49e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: uncomment to export the metrics tables to CSV files.\n",
    "# output_dir = PROJECT_ROOT / 'notebooks' / 'outputs'\n",
    "# output_dir.mkdir(parents=True, exist_ok=True)\n",
    "# for name, payload in results.items():\n",
    "#     payload['metrics'].to_csv(output_dir / f'{name}_link_metrics.csv', index=False)\n",
    "# print(f'Saved metrics to {output_dir}')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
