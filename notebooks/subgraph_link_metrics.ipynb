{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8278b7c7",
   "metadata": {},
   "source": [
    "\n",
    "# Subgraph Link Prediction Heuristics\n",
    "\n",
    "This notebook computes link prediction heuristics for every prepared subgraph under `data/subgraphs`. For each subgraph we report the common neighbors count, Jaccard coefficient, Adamic–Adar index, and a network proximity z-score for all observed edges. Adjust the helper code if you want to look at non-edge pairs or persist the results to disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7ea37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import math\n",
    "import random\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb4927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 subgraph(s):\n",
      " - data/subgraphs/drug-disease\n",
      " - data/subgraphs/drug-disease-gene\n",
      " - data/subgraphs/drug-disease-gene_protein\n",
      " - data/subgraphs/drug-disease-gene_protein-pathway\n",
      " - data/subgraphs/drug-disease-gene_protein-pathway-molecular_function\n",
      " - data/subgraphs/drug-disease-pathway\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Resolve project paths so the notebook works when launched from the repo root or the notebooks folder.\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if not (PROJECT_ROOT / 'data').exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent.resolve()\n",
    "\n",
    "SUBGRAPH_ROOT = PROJECT_ROOT / 'data' / 'subgraphs'\n",
    "if not SUBGRAPH_ROOT.exists():\n",
    "    raise FileNotFoundError(f'Expected subgraphs under {SUBGRAPH_ROOT}')\n",
    "\n",
    "subgraph_dirs = sorted(p for p in SUBGRAPH_ROOT.glob('*') if p.is_dir())\n",
    "print(f\"Found {len(subgraph_dirs)} subgraph(s):\")\n",
    "for path in subgraph_dirs:\n",
    "    print(f\" - {path.relative_to(PROJECT_ROOT)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a949fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_subgraph(subgraph_path: Path):\n",
    "    \"\"\"Return node and edge tables for a subgraph directory.\"\"\"\n",
    "    nodes = pd.read_csv(subgraph_path / 'node.csv', sep='\t', dtype={'node_index': str})\n",
    "    edges = pd.read_csv(\n",
    "        subgraph_path / 'edges.csv',\n",
    "        dtype={'x_index': str, 'y_index': str, 'relation': str, 'display_relation': str},\n",
    "    )\n",
    "    return nodes, edges\n",
    "\n",
    "\n",
    "def build_graph(\n",
    "    nodes: pd.DataFrame,\n",
    "    edges: pd.DataFrame,\n",
    "    *,\n",
    "    label: str | None = None,\n",
    ") -> nx.Graph:\n",
    "    \"\"\"Construct an undirected graph from node and edge tables.\"\"\"\n",
    "    graph = nx.Graph()\n",
    "    node_desc = f\"{label}: nodes\" if label else \"Nodes\"\n",
    "    for row in tqdm(\n",
    "        nodes.itertuples(index=False),\n",
    "        total=len(nodes),\n",
    "        desc=node_desc,\n",
    "        leave=False,\n",
    "    ):\n",
    "        graph.add_node(row.node_index, node_type=row.node_type, node_name=row.node_name)\n",
    "\n",
    "    edge_desc = f\"{label}: edges\" if label else \"Edges\"\n",
    "    for row in tqdm(\n",
    "        edges.itertuples(index=False),\n",
    "        total=len(edges),\n",
    "        desc=edge_desc,\n",
    "        leave=False,\n",
    "    ):\n",
    "        graph.add_edge(row.x_index, row.y_index, relation=row.relation)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def compute_link_metrics(\n",
    "    graph: nx.Graph,\n",
    "    nodes: pd.DataFrame,\n",
    "    edges: pd.DataFrame,\n",
    "    *,\n",
    "    proximity_samples: int = 200,\n",
    "    seed: int = 42,\n",
    "    label: str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compute link prediction heuristics for every observed edge.\"\"\"\n",
    "    prefix = f\"{label}: \" if label else \"\"\n",
    "\n",
    "    type_map = nodes.set_index('node_index')['node_type'].to_dict()\n",
    "    name_map = nodes.set_index('node_index')['node_name'].to_dict()\n",
    "    degree_map = dict(graph.degree())\n",
    "    nodes_by_type = nodes.groupby('node_type')['node_index'].apply(list).to_dict()\n",
    "\n",
    "    edge_rows = list(edges.itertuples(index=False))\n",
    "    edge_pairs = [(row.x_index, row.y_index) for row in edge_rows]\n",
    "\n",
    "    rng = random.Random(seed)\n",
    "    shortest_path_cache: dict[str, dict[str, int]] = {}\n",
    "\n",
    "    def shortest_path_length(u: str, v: str) -> float:\n",
    "        if u not in shortest_path_cache:\n",
    "            shortest_path_cache[u] = nx.single_source_shortest_path_length(graph, u)\n",
    "        return shortest_path_cache[u].get(v, math.inf)\n",
    "\n",
    "    baseline_cache: dict[tuple[str, str], tuple[float, float] | None] = {}\n",
    "\n",
    "    def proximity_baseline(type_u: str, type_v: str):\n",
    "        key = (type_u, type_v)\n",
    "        if key in baseline_cache:\n",
    "            return baseline_cache[key]\n",
    "\n",
    "        candidates_u = nodes_by_type.get(type_u, [])\n",
    "        candidates_v = nodes_by_type.get(type_v, [])\n",
    "        if not candidates_u or not candidates_v:\n",
    "            baseline_cache[key] = None\n",
    "            baseline_cache[(type_v, type_u)] = None\n",
    "            return None\n",
    "\n",
    "        samples: list[float] = []\n",
    "        seen_pairs: set[tuple[str, str]] = set()\n",
    "        max_attempts = proximity_samples * 10\n",
    "        attempts = 0\n",
    "\n",
    "        progress = None\n",
    "        if proximity_samples > 0:\n",
    "            desc = f\"{prefix}Baseline {type_u}->{type_v}\"\n",
    "            progress = tqdm(total=proximity_samples, desc=desc, leave=False)\n",
    "\n",
    "        try:\n",
    "            while len(samples) < proximity_samples and attempts < max_attempts:\n",
    "                attempts += 1\n",
    "                u = rng.choice(candidates_u)\n",
    "                v = rng.choice(candidates_v)\n",
    "                if u == v:\n",
    "                    continue\n",
    "                pair_key = (u, v) if type_u != type_v else tuple(sorted((u, v)))\n",
    "                if pair_key in seen_pairs:\n",
    "                    continue\n",
    "                seen_pairs.add(pair_key)\n",
    "\n",
    "                dist = shortest_path_length(u, v)\n",
    "                if math.isinf(dist):\n",
    "                    continue\n",
    "                samples.append(dist)\n",
    "                if progress is not None:\n",
    "                    progress.update(1)\n",
    "        finally:\n",
    "            if progress is not None:\n",
    "                progress.close()\n",
    "\n",
    "        if len(samples) < 2:\n",
    "            baseline_cache[key] = None\n",
    "            baseline_cache[(type_v, type_u)] = None\n",
    "            return None\n",
    "\n",
    "        mean_dist = float(np.mean(samples))\n",
    "        std_dist = float(np.std(samples, ddof=1)) if len(samples) > 1 else 0.0\n",
    "        baseline_cache[key] = (mean_dist, std_dist)\n",
    "        baseline_cache[(type_v, type_u)] = (mean_dist, std_dist)\n",
    "        return baseline_cache[key]\n",
    "\n",
    "    jaccard_scores = {}\n",
    "    for u, v, score in tqdm(\n",
    "        nx.jaccard_coefficient(graph, edge_pairs),\n",
    "        total=len(edge_pairs),\n",
    "        desc=f\"{prefix}Jaccard\",\n",
    "        leave=False,\n",
    "    ):\n",
    "        jaccard_scores[(u, v)] = score\n",
    "        jaccard_scores[(v, u)] = score\n",
    "\n",
    "    adamic_scores = {}\n",
    "    for u, v, score in tqdm(\n",
    "        nx.adamic_adar_index(graph, edge_pairs),\n",
    "        total=len(edge_pairs),\n",
    "        desc=f\"{prefix}Adamic-Adar\",\n",
    "        leave=False,\n",
    "    ):\n",
    "        adamic_scores[(u, v)] = score\n",
    "        adamic_scores[(v, u)] = score\n",
    "\n",
    "    records = []\n",
    "    edge_desc = f\"{prefix}Scoring edges\"\n",
    "    for row in tqdm(edge_rows, total=len(edge_rows), desc=edge_desc, leave=False):\n",
    "        u = row.x_index\n",
    "        v = row.y_index\n",
    "        source_type = type_map.get(u)\n",
    "        target_type = type_map.get(v)\n",
    "\n",
    "        cn_count = sum(1 for _ in nx.common_neighbors(graph, u, v))\n",
    "\n",
    "        jaccard_score = jaccard_scores.get((u, v), float('nan'))\n",
    "        adamic_score = adamic_scores.get((u, v), float('nan'))\n",
    "\n",
    "        sp_length = shortest_path_length(u, v)\n",
    "        if math.isinf(sp_length):\n",
    "            proximity_z = None\n",
    "            baseline_mean = None\n",
    "            baseline_std = None\n",
    "            sp_value = None\n",
    "        else:\n",
    "            baseline = proximity_baseline(source_type, target_type)\n",
    "            if baseline is None:\n",
    "                proximity_z = None\n",
    "                baseline_mean = None\n",
    "                baseline_std = None\n",
    "            else:\n",
    "                mean_dist, std_dist = baseline\n",
    "                if std_dist > 0:\n",
    "                    proximity_z = (sp_length - mean_dist) / std_dist\n",
    "                else:\n",
    "                    proximity_z = 0.0\n",
    "                baseline_mean = mean_dist\n",
    "                baseline_std = std_dist\n",
    "            sp_value = sp_length\n",
    "\n",
    "        records.append(\n",
    "            {\n",
    "                'source_index': u,\n",
    "                'target_index': v,\n",
    "                'source_type': source_type,\n",
    "                'target_type': target_type,\n",
    "                'source_name': name_map.get(u),\n",
    "                'target_name': name_map.get(v),\n",
    "                'relation': row.relation,\n",
    "                'common_neighbors': cn_count,\n",
    "                'jaccard_coefficient': jaccard_score,\n",
    "                'adamic_adar_index': adamic_score,\n",
    "                'shortest_path_length': sp_value,\n",
    "                'network_proximity_z': proximity_z,\n",
    "                'proximity_baseline_mean': baseline_mean,\n",
    "                'proximity_baseline_std': baseline_std,\n",
    "                'source_degree': degree_map.get(u),\n",
    "                'target_degree': degree_map.get(v),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame.from_records(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6975d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6384bb661c0446babb4e7b4254a5632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Subgraphs:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381eabc125494dfc8e7db9dffa95ca34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "drug-disease: nodes:   0%|          | 0/25037 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a6f0077b684e2dbbd7cfac3ad93372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "drug-disease: edges:   0%|          | 0/2822278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e82d3528b64764887e8edc4de0cb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "drug-disease: Jaccard:   0%|          | 0/2822278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd419ee66cc4954b4464ead104f0500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "drug-disease: Adamic-Adar:   0%|          | 0/2822278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0c8958665046a695a11e3b2e57d1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "drug-disease: Scoring edges:   0%|          | 0/2822278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559b27db749d4fcf8cbcc6760dd5a627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "drug-disease: Baseline drug->disease:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29dd636b5a0742bf8e2e01be1de59563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "drug-disease: Baseline drug->drug:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9374c12f7e0c45e2abe841356881c1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "drug-disease: Baseline disease->disease:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m nodes_df, edges_df = load_subgraph(subgraph_path)\n\u001b[32m      5\u001b[39m graph = build_graph(nodes_df, edges_df, label=label)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m metrics_df = \u001b[43mcompute_link_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medges_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m results[label] = {\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mgraph\u001b[39m\u001b[33m'\u001b[39m: graph,\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnodes\u001b[39m\u001b[33m'\u001b[39m: nodes_df,\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33medges\u001b[39m\u001b[33m'\u001b[39m: edges_df,\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m'\u001b[39m: metrics_df,\n\u001b[32m     12\u001b[39m }\n\u001b[32m     13\u001b[39m tqdm.write(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mComputed metrics for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(metrics_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m edge(s)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 157\u001b[39m, in \u001b[36mcompute_link_metrics\u001b[39m\u001b[34m(graph, nodes, edges, proximity_samples, seed, label)\u001b[39m\n\u001b[32m    154\u001b[39m jaccard_score = jaccard_scores.get((u, v), \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m    155\u001b[39m adamic_score = adamic_scores.get((u, v), \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m sp_length = \u001b[43mshortest_path_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m math.isinf(sp_length):\n\u001b[32m    159\u001b[39m     proximity_z = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mcompute_link_metrics.<locals>.shortest_path_length\u001b[39m\u001b[34m(u, v)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mshortest_path_length\u001b[39m(u: \u001b[38;5;28mstr\u001b[39m, v: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m u \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m shortest_path_cache:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         shortest_path_cache[u] = \u001b[43mnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msingle_source_shortest_path_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m shortest_path_cache[u].get(v, math.inf)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<class 'networkx.utils.decorators.argmap'> compilation 20:3\u001b[39m, in \u001b[36margmap_single_source_shortest_path_length_17\u001b[39m\u001b[34m(G, source, cutoff, backend, **backend_kwargs)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbz2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgzip\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/prime-kg-venv/lib/python3.11/site-packages/networkx/utils/backends.py:535\u001b[39m, in \u001b[36m_dispatchable._call_if_no_backends_installed\u001b[39m\u001b[34m(self, backend, *args, **kwargs)\u001b[39m\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnetworkx\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.backends:\n\u001b[32m    530\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    531\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not implemented by \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnetworkx\u001b[39m\u001b[33m'\u001b[39m\u001b[33m backend. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    532\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis function is included in NetworkX as an API to dispatch to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    533\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mother backends.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    534\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43morig_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/prime-kg-venv/lib/python3.11/site-packages/networkx/algorithms/shortest_paths/unweighted.py:58\u001b[39m, in \u001b[36msingle_source_shortest_path_length\u001b[39m\u001b[34m(G, source, cutoff)\u001b[39m\n\u001b[32m     56\u001b[39m     cutoff = \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33minf\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     57\u001b[39m nextlevel = [source]\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(_single_shortest_path_length(G._adj, nextlevel, cutoff))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/prime-kg-venv/lib/python3.11/site-packages/networkx/algorithms/shortest_paths/unweighted.py:-1\u001b[39m, in \u001b[36m_single_shortest_path_length\u001b[39m\u001b[34m(adj, firstlevel, cutoff)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "results = {}\n",
    "for subgraph_path in tqdm(subgraph_dirs, desc='Subgraphs', leave=False):\n",
    "    label = subgraph_path.name\n",
    "    nodes_df, edges_df = load_subgraph(subgraph_path)\n",
    "    graph = build_graph(nodes_df, edges_df, label=label)\n",
    "    metrics_df = compute_link_metrics(graph, nodes_df, edges_df, label=label)\n",
    "    results[label] = {\n",
    "        'graph': graph,\n",
    "        'nodes': nodes_df,\n",
    "        'edges': edges_df,\n",
    "        'metrics': metrics_df,\n",
    "    }\n",
    "    tqdm.write(f\"Computed metrics for {label}: {len(metrics_df)} edge(s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preview the first few rows for one subgraph.\n",
    "example_key = next(iter(results))\n",
    "results[example_key]['metrics'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d49e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: uncomment to export the metrics tables to CSV files.\n",
    "# output_dir = PROJECT_ROOT / 'notebooks' / 'outputs'\n",
    "# output_dir.mkdir(parents=True, exist_ok=True)\n",
    "# for name, payload in results.items():\n",
    "#     payload['metrics'].to_csv(output_dir / f'{name}_link_metrics.csv', index=False)\n",
    "# print(f'Saved metrics to {output_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce4311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ds/lq3mp6sd4rz66vwvs754yntr0000gn/T/ipykernel_98712/3303022855.py:33: DtypeWarning: Columns (1,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = normalize_edges(pd.read_csv(train_path))\n",
      "/var/folders/ds/lq3mp6sd4rz66vwvs754yntr0000gn/T/ipykernel_98712/3303022855.py:34: DtypeWarning: Columns (1,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  val_df   = normalize_edges(pd.read_csv(val_path))\n",
      "/var/folders/ds/lq3mp6sd4rz66vwvs754yntr0000gn/T/ipykernel_98712/3303022855.py:35: DtypeWarning: Columns (1,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_df  = normalize_edges(pd.read_csv(test_path))\n",
      "Indexing types:   4%|▍         | 606785/15390948 [00:07<03:07, 78782.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 80\u001b[39m\n\u001b[32m     75\u001b[39m         A_types[t] = csr_matrix((data, (rows, cols)),\n\u001b[32m     76\u001b[39m                                 shape=(n_nodes, \u001b[38;5;28mlen\u001b[39m(col_index)),\n\u001b[32m     77\u001b[39m                                 dtype=np.uint8)\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m A_types\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m type_col_index = \u001b[43mbuild_type_col_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_undir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbor_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m A_types = build_incidence_by_type(train_undir, node_index, type_col_index)\n\u001b[32m     82\u001b[39m deg_cache = {t: np.asarray(A.sum(axis=\u001b[32m1\u001b[39m)).ravel() \u001b[38;5;28;01mfor\u001b[39;00m t, A \u001b[38;5;129;01min\u001b[39;00m A_types.items()}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mbuild_type_col_index\u001b[39m\u001b[34m(train_df, node_index, neighbor_types)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_type_col_index\u001b[39m(train_df, node_index, neighbor_types):\n\u001b[32m     54\u001b[39m     type_to_entities = {t: \u001b[38;5;28mset\u001b[39m() \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m neighbor_types}\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mIndexing types\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdst_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtype_to_entities\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtype_to_entities\u001b[49m\u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdst_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdst\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/prime-kg-venv/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/prime-kg-venv/lib/python3.11/site-packages/pandas/core/frame.py:1411\u001b[39m, in \u001b[36mDataFrame.iterrows\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1409\u001b[39m klass = \u001b[38;5;28mself\u001b[39m._constructor_sliced\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.index, \u001b[38;5;28mself\u001b[39m.values):\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     s = \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1412\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m k, s\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/prime-kg-venv/lib/python3.11/site-packages/pandas/core/series.py:474\u001b[39m, in \u001b[36mSeries.__init__\u001b[39m\u001b[34m(self, data, index, dtype, name, copy, fastpath)\u001b[39m\n\u001b[32m    472\u001b[39m manager = get_option(\u001b[33m\"\u001b[39m\u001b[33mmode.data_manager\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33mblock\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     data = \u001b[43mSingleBlockManager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    476\u001b[39m     data = SingleArrayManager.from_array(data, index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/prime-kg-venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:1940\u001b[39m, in \u001b[36mSingleBlockManager.from_array\u001b[39m\u001b[34m(cls, array, index)\u001b[39m\n\u001b[32m   1936\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1937\u001b[39m \u001b[33;03mConstructor for if we have an array that is not yet a Block.\u001b[39;00m\n\u001b[32m   1938\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1939\u001b[39m block = new_block(array, placement=\u001b[38;5;28mslice\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(index)), ndim=\u001b[32m1\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/prime-kg-venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:1915\u001b[39m, in \u001b[36mSingleBlockManager.__init__\u001b[39m\u001b[34m(self, block, axis, refs, parent, verify_integrity, fastpath)\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.blocks = (block,)\n\u001b[32m   1914\u001b[39m \u001b[38;5;28mself\u001b[39m.refs = refs\n\u001b[32m-> \u001b[39m\u001b[32m1915\u001b[39m \u001b[38;5;28mself\u001b[39m.parent = parent \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_using_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/prime-kg-venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:2433\u001b[39m, in \u001b[36m_using_copy_on_write\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   2427\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mfancy\u001b[39m\u001b[33m\"\u001b[39m, indexer, \u001b[38;5;28mlen\u001b[39m(indexer)\n\u001b[32m   2430\u001b[39m _mode_options = _global_config[\u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m2433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_using_copy_on_write\u001b[39m():\n\u001b[32m   2434\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _mode_options[\u001b[33m\"\u001b[39m\u001b[33mcopy_on_write\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- Typed Jaccard baseline for TxGNN-style link prediction ---\n",
    "# Compute Jaccard scores for held-out drug–disease pairs using train/val/test CSVs.\n",
    "# Author: GPT-5 (network-analysis project)\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Set\n",
    "from tqdm import tqdm   # <--- added tqdm import\n",
    "\n",
    "# --- CONFIG --------------------------------------------------------------------\n",
    "train_path = \"../data/subgraphs/drug-disease/full_graph_42/train.csv\"\n",
    "val_path   = \"../data/subgraphs/drug-disease/full_graph_42/valid.csv\"\n",
    "test_path  = \"../data/subgraphs/drug-disease/full_graph_42/test.csv\"\n",
    "out_path   = \"../data/subgraphs/drug-disease/scores_jaccard.csv\"\n",
    "\n",
    "neighbor_types = [\"gene/protein\", \"phenotype\", \"exposure\", \"disease\", \"pathway\", \"anatomy\"]\n",
    "neg_per_pos = 1        # negatives per positive\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "# --- LOAD & NORMALIZE ----------------------------------------------------------\n",
    "def normalize_edges(df):\n",
    "    df = df.rename(columns={\n",
    "        \"x_id\": \"src\", \"y_id\": \"dst\",\n",
    "        \"x_type\": \"src_type\", \"y_type\": \"dst_type\",\n",
    "        \"relation\": \"relation\"\n",
    "    })\n",
    "    return df[[\"src\", \"dst\", \"src_type\", \"dst_type\", \"relation\"]]\n",
    "\n",
    "train_df = normalize_edges(pd.read_csv(train_path))\n",
    "val_df   = normalize_edges(pd.read_csv(val_path))\n",
    "test_df  = normalize_edges(pd.read_csv(test_path))\n",
    "\n",
    "def make_undirected(df):\n",
    "    df_rev = df.rename(columns={\"src\": \"dst\", \"dst\": \"src\",\n",
    "                                \"src_type\": \"dst_type\", \"dst_type\": \"src_type\"})\n",
    "    return pd.concat([df, df_rev], ignore_index=True)\n",
    "\n",
    "train_undir = make_undirected(train_df)\n",
    "\n",
    "# --- INDEXING ------------------------------------------------------------------\n",
    "def build_node_index(train_df):\n",
    "    nodes = pd.Index(pd.concat([train_df[\"src\"], train_df[\"dst\"]]).unique())\n",
    "    return {n: i for i, n in enumerate(nodes)}\n",
    "\n",
    "node_index = build_node_index(train_undir)\n",
    "n_nodes = len(node_index)\n",
    "\n",
    "# --- BUILD INCIDENCE MATRICES BY TYPE ------------------------------------------\n",
    "def build_type_col_index(train_df, node_index, neighbor_types):\n",
    "    type_to_entities = {t: set() for t in neighbor_types}\n",
    "    for _, r in tqdm(train_df.iterrows(), total=len(train_df), desc=\"Indexing types\"):\n",
    "        if r[\"dst_type\"] in type_to_entities:\n",
    "            type_to_entities[r[\"dst_type\"]].add(r[\"dst\"])\n",
    "        if r[\"src_type\"] in type_to_entities:\n",
    "            type_to_entities[r[\"src_type\"]].add(r[\"src\"])\n",
    "    return {t: {e: j for j, e in enumerate(sorted(ents))}\n",
    "            for t, ents in type_to_entities.items() if ents}\n",
    "\n",
    "def build_incidence_by_type(train_df, node_index, type_col_index):\n",
    "    n_nodes = len(node_index)\n",
    "    A_types = {}\n",
    "    for t, col_index in type_col_index.items():\n",
    "        rows, cols = [], []\n",
    "        for _, r in tqdm(train_df.iterrows(), total=len(train_df), desc=f\"Building {t}\"):\n",
    "            u = node_index.get(r[\"src\"])\n",
    "            if u is None: continue\n",
    "            if r[\"dst_type\"] == t and r[\"dst\"] in col_index:\n",
    "                rows.append(u)\n",
    "                cols.append(col_index[r[\"dst\"]])\n",
    "        data = np.ones(len(rows), dtype=np.uint8)\n",
    "        A_types[t] = csr_matrix((data, (rows, cols)),\n",
    "                                shape=(n_nodes, len(col_index)),\n",
    "                                dtype=np.uint8)\n",
    "    return A_types\n",
    "\n",
    "type_col_index = build_type_col_index(train_undir, node_index, neighbor_types)\n",
    "A_types = build_incidence_by_type(train_undir, node_index, type_col_index)\n",
    "deg_cache = {t: np.asarray(A.sum(axis=1)).ravel() for t, A in A_types.items()}\n",
    "\n",
    "# --- JACCARD COMPUTATION -------------------------------------------------------\n",
    "def typed_jaccard_for_pairs(pairs, A_types, deg_cache):\n",
    "    scores = np.zeros(len(pairs))\n",
    "    for i, (u, v) in tqdm(enumerate(pairs), total=len(pairs), desc=\"Jaccard\"):\n",
    "        num = 0.0\n",
    "        den = 0.0\n",
    "        for t, A in A_types.items():\n",
    "            cn = A[u].multiply(A[v]).sum()\n",
    "            du, dv = deg_cache[t][u], deg_cache[t][v]\n",
    "            num += cn\n",
    "            den += (du + dv - cn)\n",
    "        scores[i] = (num / den) if den > 0 else 0.0\n",
    "    return scores\n",
    "\n",
    "# --- POSITIVE / NEGATIVE EDGE EXTRACTION --------------------------------------\n",
    "def pick_drug_disease_edges(df):\n",
    "    mask1 = (df[\"src_type\"] == \"drug\") & (df[\"dst_type\"] == \"disease\")\n",
    "    mask2 = (df[\"src_type\"] == \"disease\") & (df[\"dst_type\"] == \"drug\")\n",
    "    sub = df[mask1 | mask2].copy()\n",
    "    sub[\"drug\"] = np.where(sub[\"src_type\"] == \"drug\", sub[\"src\"], sub[\"dst\"])\n",
    "    sub[\"disease\"] = np.where(sub[\"src_type\"] == \"drug\", sub[\"dst\"], sub[\"src\"])\n",
    "    return sub[[\"drug\", \"disease\", \"relation\"]]\n",
    "\n",
    "test_dd = pick_drug_disease_edges(test_df)\n",
    "val_dd  = pick_drug_disease_edges(val_df)\n",
    "\n",
    "pos_df = pd.concat([\n",
    "    test_dd.assign(split=\"test\"),\n",
    "    val_dd.assign(split=\"val\")\n",
    "])\n",
    "\n",
    "def map_idx(n): return node_index.get(n, -1)\n",
    "pos_pairs_idx = [(map_idx(r.drug), map_idx(r.disease)) for r in pos_df.itertuples()]\n",
    "\n",
    "# Negatives: random per disease\n",
    "def sample_negatives(drug_ids, disease_ids, existing_edges, k_per_pos):\n",
    "    negs = []\n",
    "    for d in tqdm(disease_ids, desc=\"Sampling negatives\"):\n",
    "        for _ in range(k_per_pos):\n",
    "            tries = 0\n",
    "            while tries < 20:\n",
    "                cand = rng.choice(drug_ids)\n",
    "                if (cand, d) not in existing_edges and (d, cand) not in existing_edges:\n",
    "                    negs.append((cand, d))\n",
    "                    break\n",
    "                tries += 1\n",
    "    return negs\n",
    "\n",
    "all_edges = pd.concat([train_df, val_df, test_df])\n",
    "edge_set = set(map(tuple, pick_drug_disease_edges(all_edges)[[\"drug\", \"disease\"]].values))\n",
    "drugs = sorted(set(pd.concat([train_df[train_df[\"src_type\"]==\"drug\"][\"src\"],\n",
    "                              train_df[train_df[\"dst_type\"]==\"drug\"][\"dst\"]]).unique()))\n",
    "diseases = sorted(pos_df[\"disease\"].unique())\n",
    "neg_pairs = sample_negatives(drugs, diseases, edge_set, neg_per_pos)\n",
    "\n",
    "neg_rows = pd.DataFrame(neg_pairs, columns=[\"drug\", \"disease\"])\n",
    "neg_rows[\"relation\"] = \"NEG\"\n",
    "neg_rows[\"split\"] = \"neg\"\n",
    "neg_pairs_idx = [(map_idx(r.drug), map_idx(r.disease)) for r in neg_rows.itertuples()]\n",
    "\n",
    "# --- COMPUTE SCORES ------------------------------------------------------------\n",
    "pos_scores = typed_jaccard_for_pairs(pos_pairs_idx, A_types, deg_cache)\n",
    "neg_scores = typed_jaccard_for_pairs(neg_pairs_idx, A_types, deg_cache)\n",
    "\n",
    "out_df = pd.concat([\n",
    "    pos_df.assign(score=pos_scores),\n",
    "    neg_rows.assign(score=neg_scores)\n",
    "], ignore_index=True)\n",
    "\n",
    "# --- EVALUATE ------------------------------------------------------------------\n",
    "y_true = (out_df[\"relation\"] != \"NEG\").astype(int)\n",
    "y_pred = out_df[\"score\"]\n",
    "auprc = average_precision_score(y_true, y_pred)\n",
    "print(f\"AUPRC (Jaccard baseline): {auprc:.4f}\")\n",
    "\n",
    "# --- SAVE ---------------------------------------------------------------------\n",
    "out_df.to_csv(out_path, index=False)\n",
    "print(f\"Saved results to {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prime-kg-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
