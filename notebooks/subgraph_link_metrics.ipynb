{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8278b7c7",
   "metadata": {},
   "source": [
    "\n",
    "# Subgraph Link Prediction Heuristics\n",
    "\n",
    "This notebook computes link prediction heuristics for every prepared subgraph under `data/subgraphs`. For each subgraph we report the common neighbors count, Jaccard coefficient, Adamicâ€“Adar index, and a network proximity z-score for all observed edges. Adjust the helper code if you want to look at non-edge pairs or persist the results to disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7ea37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import math\n",
    "import random\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb4927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 subgraph(s):\n",
      " - data/subgraphs/drug-disease\n",
      " - data/subgraphs/drug-disease-gene\n",
      " - data/subgraphs/drug-disease-gene_protein\n",
      " - data/subgraphs/drug-disease-gene_protein-pathway\n",
      " - data/subgraphs/drug-disease-gene_protein-pathway-molecular_function\n",
      " - data/subgraphs/drug-disease-pathway\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Resolve project paths so the notebook works when launched from the repo root or the notebooks folder.\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if not (PROJECT_ROOT / 'data').exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent.resolve()\n",
    "\n",
    "SUBGRAPH_ROOT = PROJECT_ROOT / 'data' / 'subgraphs'\n",
    "if not SUBGRAPH_ROOT.exists():\n",
    "    raise FileNotFoundError(f'Expected subgraphs under {SUBGRAPH_ROOT}')\n",
    "\n",
    "subgraph_dirs = sorted(p for p in SUBGRAPH_ROOT.glob('*') if p.is_dir())\n",
    "print(f\"Found {len(subgraph_dirs)} subgraph(s):\")\n",
    "for path in subgraph_dirs:\n",
    "    print(f\" - {path.relative_to(PROJECT_ROOT)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a949fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_subgraph(subgraph_path: Path):\n",
    "    \"\"\"Return node and edge tables for a subgraph directory.\"\"\"\n",
    "    nodes = pd.read_csv(subgraph_path / 'node.csv', sep='\t', dtype={'node_index': str})\n",
    "    edges = pd.read_csv(\n",
    "        subgraph_path / 'edges.csv',\n",
    "        dtype={'x_index': str, 'y_index': str, 'relation': str, 'display_relation': str},\n",
    "    )\n",
    "    return nodes, edges\n",
    "\n",
    "\n",
    "def build_graph(\n",
    "    nodes: pd.DataFrame,\n",
    "    edges: pd.DataFrame,\n",
    "    *,\n",
    "    label: str | None = None,\n",
    ") -> nx.Graph:\n",
    "    \"\"\"Construct an undirected graph from node and edge tables.\"\"\"\n",
    "    graph = nx.Graph()\n",
    "    node_desc = f\"{label}: nodes\" if label else \"Nodes\"\n",
    "    for row in tqdm(\n",
    "        nodes.itertuples(index=False),\n",
    "        total=len(nodes),\n",
    "        desc=node_desc,\n",
    "        leave=False,\n",
    "    ):\n",
    "        graph.add_node(row.node_index, node_type=row.node_type, node_name=row.node_name)\n",
    "\n",
    "    edge_desc = f\"{label}: edges\" if label else \"Edges\"\n",
    "    for row in tqdm(\n",
    "        edges.itertuples(index=False),\n",
    "        total=len(edges),\n",
    "        desc=edge_desc,\n",
    "        leave=False,\n",
    "    ):\n",
    "        graph.add_edge(row.x_index, row.y_index, relation=row.relation)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def compute_link_metrics(\n",
    "    graph: nx.Graph,\n",
    "    nodes: pd.DataFrame,\n",
    "    edges: pd.DataFrame,\n",
    "    *,\n",
    "    proximity_samples: int = 200,\n",
    "    seed: int = 42,\n",
    "    label: str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compute link prediction heuristics for every observed edge.\"\"\"\n",
    "    prefix = f\"{label}: \" if label else \"\"\n",
    "\n",
    "    type_map = nodes.set_index('node_index')['node_type'].to_dict()\n",
    "    name_map = nodes.set_index('node_index')['node_name'].to_dict()\n",
    "    degree_map = dict(graph.degree())\n",
    "    nodes_by_type = nodes.groupby('node_type')['node_index'].apply(list).to_dict()\n",
    "\n",
    "    edge_rows = list(edges.itertuples(index=False))\n",
    "    edge_pairs = [(row.x_index, row.y_index) for row in edge_rows]\n",
    "\n",
    "    rng = random.Random(seed)\n",
    "    shortest_path_cache: dict[str, dict[str, int]] = {}\n",
    "\n",
    "    def shortest_path_length(u: str, v: str) -> float:\n",
    "        if u not in shortest_path_cache:\n",
    "            shortest_path_cache[u] = nx.single_source_shortest_path_length(graph, u)\n",
    "        return shortest_path_cache[u].get(v, math.inf)\n",
    "\n",
    "    baseline_cache: dict[tuple[str, str], tuple[float, float] | None] = {}\n",
    "\n",
    "    def proximity_baseline(type_u: str, type_v: str):\n",
    "        key = (type_u, type_v)\n",
    "        if key in baseline_cache:\n",
    "            return baseline_cache[key]\n",
    "\n",
    "        candidates_u = nodes_by_type.get(type_u, [])\n",
    "        candidates_v = nodes_by_type.get(type_v, [])\n",
    "        if not candidates_u or not candidates_v:\n",
    "            baseline_cache[key] = None\n",
    "            baseline_cache[(type_v, type_u)] = None\n",
    "            return None\n",
    "\n",
    "        samples: list[float] = []\n",
    "        seen_pairs: set[tuple[str, str]] = set()\n",
    "        max_attempts = proximity_samples * 10\n",
    "        attempts = 0\n",
    "\n",
    "        progress = None\n",
    "        if proximity_samples > 0:\n",
    "            desc = f\"{prefix}Baseline {type_u}->{type_v}\"\n",
    "            progress = tqdm(total=proximity_samples, desc=desc, leave=False)\n",
    "\n",
    "        try:\n",
    "            while len(samples) < proximity_samples and attempts < max_attempts:\n",
    "                attempts += 1\n",
    "                u = rng.choice(candidates_u)\n",
    "                v = rng.choice(candidates_v)\n",
    "                if u == v:\n",
    "                    continue\n",
    "                pair_key = (u, v) if type_u != type_v else tuple(sorted((u, v)))\n",
    "                if pair_key in seen_pairs:\n",
    "                    continue\n",
    "                seen_pairs.add(pair_key)\n",
    "\n",
    "                dist = shortest_path_length(u, v)\n",
    "                if math.isinf(dist):\n",
    "                    continue\n",
    "                samples.append(dist)\n",
    "                if progress is not None:\n",
    "                    progress.update(1)\n",
    "        finally:\n",
    "            if progress is not None:\n",
    "                progress.close()\n",
    "\n",
    "        if len(samples) < 2:\n",
    "            baseline_cache[key] = None\n",
    "            baseline_cache[(type_v, type_u)] = None\n",
    "            return None\n",
    "\n",
    "        mean_dist = float(np.mean(samples))\n",
    "        std_dist = float(np.std(samples, ddof=1)) if len(samples) > 1 else 0.0\n",
    "        baseline_cache[key] = (mean_dist, std_dist)\n",
    "        baseline_cache[(type_v, type_u)] = (mean_dist, std_dist)\n",
    "        return baseline_cache[key]\n",
    "\n",
    "    jaccard_scores = {}\n",
    "    for u, v, score in tqdm(\n",
    "        nx.jaccard_coefficient(graph, edge_pairs),\n",
    "        total=len(edge_pairs),\n",
    "        desc=f\"{prefix}Jaccard\",\n",
    "        leave=False,\n",
    "    ):\n",
    "        jaccard_scores[(u, v)] = score\n",
    "        jaccard_scores[(v, u)] = score\n",
    "\n",
    "    adamic_scores = {}\n",
    "    for u, v, score in tqdm(\n",
    "        nx.adamic_adar_index(graph, edge_pairs),\n",
    "        total=len(edge_pairs),\n",
    "        desc=f\"{prefix}Adamic-Adar\",\n",
    "        leave=False,\n",
    "    ):\n",
    "        adamic_scores[(u, v)] = score\n",
    "        adamic_scores[(v, u)] = score\n",
    "\n",
    "    records = []\n",
    "    edge_desc = f\"{prefix}Scoring edges\"\n",
    "    for row in tqdm(edge_rows, total=len(edge_rows), desc=edge_desc, leave=False):\n",
    "        u = row.x_index\n",
    "        v = row.y_index\n",
    "        source_type = type_map.get(u)\n",
    "        target_type = type_map.get(v)\n",
    "\n",
    "        cn_count = sum(1 for _ in nx.common_neighbors(graph, u, v))\n",
    "\n",
    "        jaccard_score = jaccard_scores.get((u, v), float('nan'))\n",
    "        adamic_score = adamic_scores.get((u, v), float('nan'))\n",
    "\n",
    "        sp_length = shortest_path_length(u, v)\n",
    "        if math.isinf(sp_length):\n",
    "            proximity_z = None\n",
    "            baseline_mean = None\n",
    "            baseline_std = None\n",
    "            sp_value = None\n",
    "        else:\n",
    "            baseline = proximity_baseline(source_type, target_type)\n",
    "            if baseline is None:\n",
    "                proximity_z = None\n",
    "                baseline_mean = None\n",
    "                baseline_std = None\n",
    "            else:\n",
    "                mean_dist, std_dist = baseline\n",
    "                if std_dist > 0:\n",
    "                    proximity_z = (sp_length - mean_dist) / std_dist\n",
    "                else:\n",
    "                    proximity_z = 0.0\n",
    "                baseline_mean = mean_dist\n",
    "                baseline_std = std_dist\n",
    "            sp_value = sp_length\n",
    "\n",
    "        records.append(\n",
    "            {\n",
    "                'source_index': u,\n",
    "                'target_index': v,\n",
    "                'source_type': source_type,\n",
    "                'target_type': target_type,\n",
    "                'source_name': name_map.get(u),\n",
    "                'target_name': name_map.get(v),\n",
    "                'relation': row.relation,\n",
    "                'common_neighbors': cn_count,\n",
    "                'jaccard_coefficient': jaccard_score,\n",
    "                'adamic_adar_index': adamic_score,\n",
    "                'shortest_path_length': sp_value,\n",
    "                'network_proximity_z': proximity_z,\n",
    "                'proximity_baseline_mean': baseline_mean,\n",
    "                'proximity_baseline_std': baseline_std,\n",
    "                'source_degree': degree_map.get(u),\n",
    "                'target_degree': degree_map.get(v),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame.from_records(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6975d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6384bb661c0446babb4e7b4254a5632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Subgraphs:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381eabc125494dfc8e7db9dffa95ca34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "drug-disease: nodes:   0%|          | 0/25037 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a6f0077b684e2dbbd7cfac3ad93372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "drug-disease: edges:   0%|          | 0/2822278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e82d3528b64764887e8edc4de0cb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "drug-disease: Jaccard:   0%|          | 0/2822278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "results = {}\n",
    "for subgraph_path in tqdm(subgraph_dirs, desc='Subgraphs', leave=False):\n",
    "    label = subgraph_path.name\n",
    "    nodes_df, edges_df = load_subgraph(subgraph_path)\n",
    "    graph = build_graph(nodes_df, edges_df, label=label)\n",
    "    metrics_df = compute_link_metrics(graph, nodes_df, edges_df, label=label)\n",
    "    results[label] = {\n",
    "        'graph': graph,\n",
    "        'nodes': nodes_df,\n",
    "        'edges': edges_df,\n",
    "        'metrics': metrics_df,\n",
    "    }\n",
    "    tqdm.write(f\"Computed metrics for {label}: {len(metrics_df)} edge(s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preview the first few rows for one subgraph.\n",
    "example_key = next(iter(results))\n",
    "results[example_key]['metrics'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d49e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: uncomment to export the metrics tables to CSV files.\n",
    "# output_dir = PROJECT_ROOT / 'notebooks' / 'outputs'\n",
    "# output_dir.mkdir(parents=True, exist_ok=True)\n",
    "# for name, payload in results.items():\n",
    "#     payload['metrics'].to_csv(output_dir / f'{name}_link_metrics.csv', index=False)\n",
    "# print(f'Saved metrics to {output_dir}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prime-kg-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
